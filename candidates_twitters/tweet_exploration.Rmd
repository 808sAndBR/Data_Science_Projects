---
title: "Tweet Exploration"
author: "Scott Brenstuhl"
date: "December 8, 2015"
output: html_document
---

```{r libraries, alert=FALSE, message = FALSE}
library(dplyr)
library(lubridate)
```

```{r}
# Read in tweets produced by twitter_scraper.py
tweets <- read.csv('canidate_tweets.csv', stringsAsFactors = FALSE)

# convert Twitters API format to one we can work with
tweets$datetime <- paste(substr(tweets$created,27,31),
                         substr(tweets$created, 5, 19)) %>%
    ymd_hms() %>%
    as.POSIXct()

tweets$is_retweet <- ifelse(grepl('*RT', tweets$text), TRUE, FALSE)

# retain raw version in case its useful later
tweets$rawtext <- tweets$text

tweets$text <- gsub('\\\n',' ', tweets$text)

# Grab all links before removing punctuation charicters
tweets$links <- strsplit(tolower(tweets$text), " ") %>%
    lapply(grep, pattern= 'http', value = TRUE)

# Remove puntuation that isn't part of words
tweets$text <- gsub('[\\.\\\",!?:]', '', tweets$text)

tweets$hashtags <- strsplit(tolower(tweets$text), " ") %>%
    lapply(grep, pattern= '#', value = TRUE)

tweets$hashtags[tweets$hashtags == 'character(0)'] <- NA

tweets$mentions <- strsplit(tolower(tweets$text), " ") %>%
    lapply(grep, pattern= '@', value = TRUE)

# Split all the words out to work with, but ignore things that are in their own column
# should add quotation mark
tweets$split <- strsplit(tolower(tweets$text), " ") %>%
    lapply(grep, pattern= 'http|@|#|^(rt)$', value = TRUE, invert=TRUE)

```

```{r}
blobs <- group_by(subset(tweets, tweets$is_retweet==FALSE), canidate) %>%
    summarise(count = n(), 
              hashtags = paste(unlist(hashtags), collapse = ","),
              words = strsplit(paste(unlist(split), collapse = ","), ","),
              mentions = paste(unlist(mentions), collapse = ","),
              retweets = sum(retweets),
              likes = sum(likes)
              )


blobs$word_counts <- lapply(blobs$words, table) %>%
    lapply(sort, decreasing = TRUE)
```
```{r}
for(i in 1:nrow(blobs)){
    print(c(blobs$canidate[i], round(length(blobs$word_counts[[i]])/sum(blobs$word_counts[[i]]),4)*100))
}


for(i in 1:nrow(blobs)){
    print(c(blobs$canidate[i], 
            blobs$word_counts[[i]]['obama'], 
            blobs$word_counts[[i]]['president']))
}

# Bernie lololol
for(i in 1:nrow(blobs)){
    print(c(blobs$canidate[i], 
            blobs$word_counts[[i]]['class']))
}

#how is this not higher
for(i in 1:nrow(blobs)){
    print(c(blobs$canidate[i], 
            blobs$word_counts[[i]]['gun'],
            blobs$word_counts[[i]]['guns'],
            blobs$word_counts[[i]]['second'],
            blobs$word_counts[[i]]['amendment']
            ))
}


for(i in 1:nrow(blobs)){
    print(c(blobs$canidate[i], 
            blobs$word_counts[[i]]['me'],
            blobs$word_counts[[i]]['i'],
            blobs$word_counts[[i]]['we']))
}

length(blobs$word_counts)


blobs$word_counts[[2]][1:50]
length(blobs$word_counts[[1]])


sort(table(strsplit(blobs$words[1], ",")))
?strsplit
Filter(function(x) !identical(character(0),x), blobs$hashtags[1])
View(head(blobs))
names(tweets)


```


